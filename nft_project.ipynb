{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c7922c2144ccea",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "OPENSEA_API = os.getenv('OPENSEA_API_KEY')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa5284aa8f0e0fde",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def requests_session_with_retries():\n",
    "    session = requests.Session()\n",
    "    retries = Retry(total=5,  # Total number of retries to allow.\n",
    "                    backoff_factor=1,  # A backoff factor to apply between attempts.\n",
    "                    status_forcelist=[500, 502, 503, 504])  # A set of HTTP status codes that we should force a retry on.\n",
    "    adapter = HTTPAdapter(max_retries=retries)\n",
    "    session.mount('http://', adapter)\n",
    "    session.mount('https://', adapter)\n",
    "    return session"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7303d4ef157f7d84",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def fetch_api_data_paginated(base_url, headers=None, data_key='asset_events'):\n",
    "    session = requests_session_with_retries()\n",
    "    all_data = []\n",
    "    url = base_url\n",
    "    \n",
    "    while url:\n",
    "        print(f\"Requesting URL: {url}\")\n",
    "        response = session.get(url, headers=headers, timeout=30)\n",
    "       \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            page_data = data.get(data_key, [])\n",
    "            all_data.extend(page_data)\n",
    "            next_cursor = data.get('next', \"\")\n",
    "            print(next_cursor)\n",
    "            if next_cursor:\n",
    "                url = f\"{base_url}?next={next_cursor}\"\n",
    "            else:\n",
    "                url = None\n",
    "        else:\n",
    "            print(f\"Failed to fetch data from {url} - Status Code: {response.status_code}\")\n",
    "            break\n",
    "        \n",
    "    return pd.json_normalize(all_data)  # Convert the aggregated data to a DataFrame\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4be1bd239dd2037a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import pandas as pd\n",
    "# \n",
    "# def requests_session_with_retries():\n",
    "#     session = requests.Session()\n",
    "#     retries = Retry(total=5, backoff_factor=1, status_forcelist=[500, 502, 503, 504])\n",
    "#     adapter = HTTPAdapter(max_retries=retries)\n",
    "#     session.mount('http://', adapter)\n",
    "#     session.mount('https://', adapter)\n",
    "#     return session\n",
    "# \n",
    "# def fetch_api_data_paginated(base_url, headers=None, after=None, event_type=None, data_key='asset_events'):\n",
    "#     session = requests_session_with_retries()\n",
    "#     all_data = []\n",
    "#     params = {\n",
    "#         \"after\": after,  # Add the 'after' timestamp to the query parameters if provided\n",
    "#         \"event_type\": event_type  # Add the 'event_type' to the query parameters if provided\n",
    "#     }\n",
    "#     counter = 0\n",
    "# \n",
    "#     while counter <= 100:\n",
    "#         print(f\"Requesting URL: {base_url} with params: {params}\")\n",
    "#         response = session.get(base_url, headers=headers, params=params, timeout=30)\n",
    "# \n",
    "#         if response.status_code == 200:\n",
    "#             data = response.json()\n",
    "#             page_data = data.get(data_key, [])\n",
    "#             all_data.extend(page_data)\n",
    "#             next_cursor = data.get('next', None)\n",
    "#             print(\"Going to next page\")\n",
    "#             if next_cursor:\n",
    "#                 params['cursor'] = next_cursor  # Update the 'cursor' in params for pagination\n",
    "#             else:\n",
    "#                 break  # Exit loop if there's no 'next' cursor\n",
    "#         else:\n",
    "#             print(f\"Failed to fetch data from {base_url} - Status Code: {response.status_code}\")\n",
    "#             break\n",
    "#         counter += 1\n",
    "# \n",
    "#     return pd.json_normalize(all_data)  # Convert the aggregated data to a DataFrame\n",
    "# \n",
    "# # Example usage\n",
    "# headers = {\n",
    "#     \"accept\": \"application/json\",\n",
    "#     \"x-api-key\": \"29b6c9b1120748878ac7f50821ec4d0b\"\n",
    "# }\n",
    "# base_url = \"https://api.opensea.io/api/v2/events/collection/collection_slug\"  # Replace with your actual URL\n",
    "# after_timestamp = \"1672531200\"  # Replace with your actual timestamp or None\n",
    "# event_type = None  # Specify an event type if desired\n",
    "# \n",
    "# # Fetching the data\n",
    "# data_df = fetch_api_data_paginated(base_url, headers, after=after_timestamp, event_type=event_type)\n",
    "# print(data_df)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb5ce8a661fd86a4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Function to fetch data from an API\n",
    "def fetch_api_data(url, headers=None):\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        df = pd.json_normalize(data, max_level=1)\n",
    "        return df\n",
    "    else:\n",
    "        print(f\"Failed to fetch data from {url}\")\n",
    "        return {}\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a5340f5540ba0372",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# USER CHOOSES COLLECTION\n",
    "collection_slug = input(\"Enter the collection: \")\n",
    "APR = input(\"Enter your target APR: \")\n",
    "\n",
    "\n",
    "\n",
    "# API's\n",
    "get_collection_stats = f\"https://api.opensea.io/api/v2/collections/{collection_slug}/stats\"\n",
    "get_collection = f\"https://api.opensea.io/api/v2/collections/{collection_slug}\"\n",
    "get_events_by_collection = f\"https://api.opensea.io/api/v2/events/collection/{collection_slug}\"\n",
    "get_nft_by_collection = f\"https://api.opensea.io/api/v2/collection/{collection_slug}/nfts\"\n",
    "get_traits = f\"https://api.opensea.io/api/v2/traits/{collection_slug}\"\n",
    "\n",
    "headers = {\"accept\": \"application/json\", \"x-api-key\": OPENSEA_API}\n",
    "\n",
    "collection_stats_df = fetch_api_data(get_collection_stats, headers)\n",
    "collection_df = fetch_api_data(get_collection, headers)\n",
    "traits_df = fetch_api_data(get_traits, headers)\n",
    "\n",
    "# events_df = fetch_api_data_paginated(get_events_by_collection, headers, data_key='asset_events')\n",
    "nft_df = fetch_api_data_paginated(get_nft_by_collection, headers, data_key='nfts')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d0b3df736497d799",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# print(events_df)\n",
    "print(nft_df)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "acbbcbdd29cda209",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Process and convert data from the first API\n",
    "df1_total = pd.DataFrame([collection_stats_df['total']])\n",
    "df1_intervals = pd.DataFrame(collection_stats_df['intervals'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b178ed8f1b2586a7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Process and convert data from the second API\n",
    "collection_fields = ['collection', 'name', 'description', 'image_url', 'banner_image_url', 'owner', 'category', 'is_disabled', 'is_nsfw', 'trait_offers_enabled', 'collection_offers_enabled', 'opensea_url', 'project_url', 'wiki_url', 'discord_url', 'telegram_url', 'twitter_username', 'instagram_username', 'total_supply', 'created_date']\n",
    "df2_collection = pd.DataFrame([{field: collection_df.get(field, '') for field in collection_fields}])\n",
    "df2_contracts = pd.DataFrame(collection_df.get('contracts', []))\n",
    "df2_fees = pd.DataFrame(collection_df.get('fees', []))\n",
    "df2_payment_tokens = pd.DataFrame(collection_df.get('payment_tokens', []))\n",
    "df2_rarity = pd.DataFrame([collection_df.get('rarity', {})])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "122a515056ec23eb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "events_normalized = []\n",
    "for event in events_df['asset_events']:\n",
    "    # Initialize event_data with event fields, excluding nft, asset, payment, criteria\n",
    "    event_data = {k: v for k, v in event.items() if k not in ['nft', 'asset', 'payment', 'criteria']}\n",
    "    \n",
    "    # Check and add nft data if present\n",
    "    if 'nft' in event and event['nft'] is not None:\n",
    "        nft_data = {'nft_' + k: v for k, v in event['nft'].items()}\n",
    "        event_data.update(nft_data)\n",
    "    \n",
    "    # Check and add asset data if present\n",
    "    elif 'asset' in event and event['asset'] is not None:\n",
    "        asset_data = {'asset_' + k: v for k, v in event['asset'].items()}\n",
    "        event_data.update(asset_data)\n",
    "    \n",
    "    # Check and include payment data if necessary and present\n",
    "    if 'payment' in event and event['payment'] is not None:\n",
    "        payment_data = {'payment_' + k: v for k, v in event['payment'].items()}\n",
    "        event_data.update(payment_data)\n",
    "    \n",
    "    events_normalized.append(event_data)\n",
    "\n",
    "df_events = pd.DataFrame(events_normalized)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc3abe56197963bf",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Export to CSV\n",
    "df1_total.to_csv('api1_total_stats.csv', index=False)\n",
    "df1_intervals.to_csv('api1_intervals_stats.csv', index=False)\n",
    "df2_collection.to_csv('api2_collection_info.csv', index=False)\n",
    "df2_contracts.to_csv('api2_collection_contracts.csv', index=False)\n",
    "df2_fees.to_csv('api2_collection_fees.csv', index=False)\n",
    "df2_payment_tokens.to_csv('api2_collection_payment_tokens.csv', index=False)\n",
    "df2_rarity.to_csv('api2_collection_rarity.csv', index=False)\n",
    "df_events.to_csv('api3_events.csv', index=False)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a06d331a75eb2126",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(df_events.head())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e0912a219284bd87",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(df1_total.head())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b78a91f641159b25",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(df1_intervals.head())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "44b427d3a267e615",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(df2_fees)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f167464f8d9a093f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(df2_rarity)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5d711d101917bb8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(df2_payment_tokens)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "43faf15a56def68c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(df2_collection)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6704cd6a0caf2001",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(df2_contracts)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1916728e4adb0eba",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4ea762e9a7e5ba4a",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
