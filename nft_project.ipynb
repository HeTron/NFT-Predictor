{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Function to fetch data from an API\n",
    "def fetch_api_data(url, headers=None):\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Failed to fetch data from {url}\")\n",
    "        return {}\n",
    "\n",
    "# Assuming these are your API URLs and headers\n",
    "url1 = \"https://api.opensea.io/api/v2/collections/mutant-ape-yacht-club/stats\"\n",
    "url2 = \"https://api.opensea.io/api/v2/collections/mutant-ape-yacht-club\"\n",
    "url3 = \"https://api.opensea.io/api/v2/events/collection/mutant-ape-yacht-club\"\n",
    "headers1 = {\"accept\": \"application/json\", \"x-api-key\": \"29b6c9b1120748878ac7f50821ec4d0b\"}\n",
    "headers2 = {\"accept\": \"application/json\", \"x-api-key\": \"29b6c9b1120748878ac7f50821ec4d0b\"}\n",
    "headers3 = {\"accept\": \"application/json\", \"x-api-key\": \"29b6c9b1120748878ac7f50821ec4d0b\"}\n",
    "\n",
    "# Fetch data from both APIs\n",
    "data1 = fetch_api_data(url1, headers1)\n",
    "data2 = fetch_api_data(url2, headers2)\n",
    "data3 = fetch_api_data(url3, headers3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T15:54:29.393934Z",
     "start_time": "2024-02-28T15:54:28.230338Z"
    }
   },
   "id": "4c7922c2144ccea",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Process and convert data from the first API\n",
    "df1_total = pd.DataFrame([data1['total']])\n",
    "df1_intervals = pd.DataFrame(data1['intervals'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T15:54:30.998335Z",
     "start_time": "2024-02-28T15:54:30.994326Z"
    }
   },
   "id": "b178ed8f1b2586a7",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Process and convert data from the second API\n",
    "collection_fields = ['collection', 'name', 'description', 'image_url', 'banner_image_url', 'owner', 'category', 'is_disabled', 'is_nsfw', 'trait_offers_enabled', 'collection_offers_enabled', 'opensea_url', 'project_url', 'wiki_url', 'discord_url', 'telegram_url', 'twitter_username', 'instagram_username', 'total_supply', 'created_date']\n",
    "df2_collection = pd.DataFrame([{field: data2.get(field, '') for field in collection_fields}])\n",
    "df2_contracts = pd.DataFrame(data2['contracts'])\n",
    "df2_fees = pd.DataFrame(data2['fees'])\n",
    "df2_payment_tokens = pd.DataFrame(data2['payment_tokens'])\n",
    "df2_rarity = pd.DataFrame([data2['rarity']])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T15:54:31.555573Z",
     "start_time": "2024-02-28T15:54:31.552493Z"
    }
   },
   "id": "122a515056ec23eb",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "events_normalized = []\n",
    "for event in data3['asset_events']:\n",
    "    # Initialize event_data with event fields, excluding nft, asset, payment, criteria\n",
    "    event_data = {k: v for k, v in event.items() if k not in ['nft', 'asset', 'payment', 'criteria']}\n",
    "    \n",
    "    # Check and add nft data if present\n",
    "    if 'nft' in event and event['nft'] is not None:\n",
    "        nft_data = {'nft_' + k: v for k, v in event['nft'].items()}\n",
    "        event_data.update(nft_data)\n",
    "    \n",
    "    # Check and add asset data if present\n",
    "    elif 'asset' in event and event['asset'] is not None:\n",
    "        asset_data = {'asset_' + k: v for k, v in event['asset'].items()}\n",
    "        event_data.update(asset_data)\n",
    "    \n",
    "    # Check and include payment data if necessary and present\n",
    "    if 'payment' in event and event['payment'] is not None:\n",
    "        payment_data = {'payment_' + k: v for k, v in event['payment'].items()}\n",
    "        event_data.update(payment_data)\n",
    "    \n",
    "    events_normalized.append(event_data)\n",
    "\n",
    "df_events = pd.DataFrame(events_normalized)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T15:54:32.369805Z",
     "start_time": "2024-02-28T15:54:32.363712Z"
    }
   },
   "id": "dc3abe56197963bf",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Export to CSV\n",
    "df1_total.to_csv('api1_total_stats.csv', index=False)\n",
    "df1_intervals.to_csv('api1_intervals_stats.csv', index=False)\n",
    "df2_collection.to_csv('api2_collection_info.csv', index=False)\n",
    "df2_contracts.to_csv('api2_collection_contracts.csv', index=False)\n",
    "df2_fees.to_csv('api2_collection_fees.csv', index=False)\n",
    "df2_payment_tokens.to_csv('api2_collection_payment_tokens.csv', index=False)\n",
    "df2_rarity.to_csv('api2_collection_rarity.csv', index=False)\n",
    "df_events.to_csv('api3_events.csv', index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T15:54:32.858400Z",
     "start_time": "2024-02-28T15:54:32.852235Z"
    }
   },
   "id": "a06d331a75eb2126",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e0912a219284bd87"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
